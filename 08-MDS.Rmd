---
output: html_document
---

# Multidimensional Scaling (MDS)

Multidimensional scaling (MDS) is a method of representing the distances among a set of items or observations.  These distances can come originally from a high-dimensional space (such as the 20-dimensional space that defines our DA data), or from a low-dimensional space.  Regardless, the goal of MDS is to find a low-dimensional (2- or 3-dimensional, usually) representation of the items in which the distances among the items is a close approximation of the original distance matrix.  

You may notice that MDS operates on the same input data as the clustering techniques we just explored in the [previous chapter][Cluster analysis].  In clustering, the goal is not to find a metric or spatial arrangement of objects, but instead to determine some smaller number of *clusters* or *groups* that summarize or explain the observed distances among our samples.  In MDS, the goal is to provide a visual and spatial representation of the distances.  

In the **R Opus**, HGH applied MDS to the DA data.  We'll explore the same approach once we review the key concept of metric and non-metric MDS.

## Metric vs non-metric

Without going into details, MDS comes in two "flavors": metric and non-metric.  In **metric MDS**, the distances among objects are taken as "metric" or measurement data: the units themselves are meaningful (another way of saying this is that they are *interval* or *ratio* data).  In this case, the underlying algorithm for MDS is very similar to PCA, in which an eigendecomposition provides the optimal solution for finding a low-dimensional representation that explains the majority of the variations in distances among samples.  Most sensory data is suitable for metric MDS, and in fact the [DISTATIS method we will use next][DISTATIS] is predicated on a proof that distances even among sorting groups are metric (specifically, Euclidean).  

For non-metric MDS, the assumption of the distances being meaningful metrics is relaxed; rather, we assume that the provided distances are only meaningful insofar as they represent ranks (they are *ordinal* data).  In this case, non-metric MDS uses a gradient-descent approach to find an approximation by extracting orthogonal dimensions while minimizing a criterion called $STRESS$.  Typically, we won't have to concern ourselves too much with non-metric MDS, but it could be useful when examining results from, for example, flash profiling (in which samples are ranked but not rated).

## Metric MDS

As usual, we begin by loading our required packages and the data.

```{r message=FALSE}
library(tidyverse)
library(here)

descriptive_data <- 
  read_csv(here("data/torriDAFinal.csv")) %>%
  # We'll make some factors as usual
  mutate(across(1:3, ~as.factor(.)))

descriptive_means <- 
  descriptive_data %>%
  # Get the means for each wine and descriptor
  group_by(ProductName) %>%
  summarize(across(where(is.numeric), ~mean(.))) %>%
  # Scale the data to unit variance
  mutate(across(where(is.numeric), ~(. - mean(.)) / sd(.)))
```

Note that as in the previous chapter, HGH scales (normalizes) the data to $\bar{x}=0$ and $s=1$, which is a choice rather than a necessity for these methods.  We will follow for consistency.

We then need to get the distances among all of our observations.

```{r}
descriptive_distances <- 
  descriptive_means %>%
  # get the rownames as we go back to older functions 
  column_to_rownames("ProductName") %>%
  dist(method = "euclidean")
```

The `cmdscale()` function in the base `R` `stats` package will do metric MDS for us.

```{r}
metric_mds <- 
  descriptive_distances %>%
  # `k` defines the # of dimensions to extract, `eig` returns the eigenvalues
  # for the spectral (eigen)decomposition
  cmdscale(k = 2, eig = TRUE)

metric_mds
```

At this point you are familiar with our plot and wrangle approach - we're going to get that `$points` table and pipe it into `ggplot2` to make a nicer looking plot.

```{r}
p_metric <- 
  metric_mds$points %>%
  as_tibble(rownames = "sample") %>%
  ggplot(aes(x = V1, y = V2)) + 
  geom_point() +
  ggrepel::geom_text_repel(aes(label = sample)) + 
  labs(x = "Dimension 1", y = "Dimension 2",
       title = "Metric MDS for wine DA data") + 
  coord_fixed() + 
  theme_bw()

p_metric
```

We can also examine a scree-plot of the eigenvalues to get a (qualitative) view of this solution.

```{r}
metric_mds$eig %>%
  as_tibble() %>%
  mutate(dim = str_c("Dimension ", row_number()),
         value = value / sum(value)) %>%
  ggplot(aes(x = dim, y = value)) + 
  geom_point() +
  geom_line(aes(group = 1)) + 
  theme_bw() + 
  labs(x = NULL, y = NULL, 
       title = "Scree plot for metric MDS")
```

We can see that, arguably, a 2-dimensional solution is not great for capturing the distances among these samples.  See that bend *after* the 3rd dimension?  That's where we'd often want to put a cut.  But this is a little academic - in practice we often only look at the first dimensions.  

Let's compare the distances from our MDS solution to the actual distances:

```{r}
# Actual distances
descriptive_distances

# Approximate distances
metric_mds$points %>%
  dist(method = "euclidean")
```

Here we can see that the distances are indeed only approximate (and not that good an approximation).

Would this get better if we went up to 3 dimensions?  We can answer that pretty easily:

```{r}
descriptive_distances %>%
  cmdscale(k = 3, eig = TRUE) %>%
  .$points %>%
  dist()
```

It does look like we're getting closer to the original distances as we go up in dimensionality - the algorithm is able to find "space" to place the points further apart.

Let's examine one more thing that will lead us to *non*-metric MDS: does our 2-dimensional MDS solution capture the correct *rank order* of distances?  In other words, is each pairwise distance in the MDS approximation in the same *order* as it would be in the actual distance matrix?

```{r}
# I am getting sick of manually tidying distance matrices, so we're going to
# enlist the `widyr` package to automate this.
library(widyr)

# Of course this creates a new set of needs, including getting our data into a
# tidy format to start with
tidy_descriptive_distances <- 
  descriptive_means %>%
  pivot_longer(-ProductName,
               names_to = "descriptor",
               values_to = "rating") %>%
  arrange(ProductName) %>%
  # The distance between `ProductName`, based on `descriptor`, with values
  # stored in `rating`
  pairwise_dist(item = ProductName, feature = descriptor, value = rating,
                upper = FALSE, method = "euclidean")

# We'll do the same thing with our MDS results
tidy_mds_distances <- 
  metric_mds$points %>%
  as_tibble(rownames = "product") %>%
  arrange(product) %>%
  pivot_longer(-product) %>%
  pairwise_dist(item = product, feature = name, value = value,
                upper = FALSE, method = "euclidean")

```

We can now look at the ranks of pairwise distances and see how many are misaligned.

```{r}
# We will rank the pairwise distances from the original data
tidy_descriptive_distances %>%
  unite(item1, item2, col = "items", sep = " <--> ") %>%
  transmute(observed_rank = items,
            distance_rank = dense_rank(distance)) %>%
  arrange(distance_rank) %>%
  # And now we'll line this up with the MDS results
  left_join(
    tidy_mds_distances %>%
      unite(item1, item2, col = "items", sep = " <--> ") %>%
      transmute(mds_rank = items,
                distance_rank = dense_rank(distance)) %>%
      arrange(distance_rank),
    # This is the line that lines them up (`by = `)
    by = "distance_rank"
  ) %>%
  # And finally we'll check which are the same
  mutate(match = observed_rank == mds_rank) %>%
  count(match)
```

That's actually very bad!  We see only 1/4 of the original distances captured by the 2-dimensional MDS solution.  Yikes.

Let's take a look and see if a non-metric MDS can do better.

## Non-metric MDS

In non-metric MDS, we assume that the observed distances are non-metric: they only represent an *ordination* of the distances among the items.  An example would be, in our actual data, that the observed distances represent estimates or opinions from our panelists:

```{r}
tidy_descriptive_distances %>%
  arrange(distance)
```
The closest samples are `C_MERLOT` and `C_ZINFANDEL`, and the second closest are `I_MERLOT` and `I_REFOSCO`.  If our distances are merely ordinations, we can only say that--we can't compare the actual "differences of distances" as we could if these were metric.  In the metric case, we could subtract the distance between `C_MERLOT` and `C_ZINFANDEL` and `I_MERLOT` and `I_REFOSCO` ($\approx4.5-3.9\approx0.6$) and say that the difference between those distances is larger than that between the second and third smallest distances (`I_MERLOT` and `I_REFOSCO` vs `C_MERLOT` and `I_MERLOT`, which is $\approx4.5-4.45\approx0$).  So we could say something like "the difference between the two closest pairs of samples is quite large, but the difference between the next two closest is approximately the same".  We can't do that with an ordination, because we only know the relative ranks:

```{r}
tidy_descriptive_distances %>%
  transmute(item1, item2, 
            distance_rank = dense_rank(distance)) %>%
  arrange(distance_rank)
```

We can no longer know if the difference between 1st and 2nd place (so to speak, of `distance_rank`) is the same as the difference between 2nd and 3rd place, and so on.  We only know that `C_MERLOT` and `C_ZINFANDEL` are closer than `I_MERLOT` and `I_REFOSCO`, and so on.

OK, with that out of the way, let's take a look at non-metric MDS.  For this, we will use the `MASS` package.  `MASS` is bundled with `R`, but is not loaded by default.  It contains many useful core functions for statistics, especially non-linear and multivariate stats.  You can learn more about it [at the authors' website](https://www.stats.ox.ac.uk/pub/MASS4/).

```{r message=FALSE}
library(MASS)

# the `isoMDS()` function will be what we use.

nonmetric_mds <-
  isoMDS(d = descriptive_distances, k = 2)
```

As mentioned, non-metric MDS is an iterative optimization problem.  We are told that the solution has "converged" because the $STRESS$ value is no longer going down with subsequent iterations.  Let's look at our results.

```{r}
p_nonmetric <-
  nonmetric_mds$points %>%
  as_tibble(rownames = "sample") %>%
  ggplot(aes(x = V1, y = V2)) + 
  geom_point() +
  ggrepel::geom_text_repel(aes(label = sample)) + 
  labs(x = "Dimension 1", y = "Dimension 2",
       title = "Non-metric MDS for wine DA data") + 
  coord_fixed() + 
  theme_bw()

p_nonmetric
```

I'd like to compare our metric and non-metric configurations.  To do so we can use the `patchwork` package, as we have before.

```{r, message = FALSE, fig.width = 8}
library(patchwork)

p_metric + p_nonmetric
```

Note that the configurations are quite similar, but with some notable sifts (e.g., the positioning of `I_MERLOT` pops out).  This makes sense: if you read the `?isoMDS` documentation, you'll see that the initial configuration for the non-metric MDS *is* the metric MDS solution, so this approach starts with our metric MDS configuration and improves on it.

Let's see if we've improved the representation of our relative ranks for distances:

```{r}
tidy_nonmetric_mds_distances <- 
  nonmetric_mds$points %>%
  as_tibble(rownames = "product") %>%
  arrange(product) %>%
  pivot_longer(-product) %>%
  pairwise_dist(item = product, feature = name, value = value,
                upper = FALSE, method = "euclidean")

tidy_descriptive_distances %>%
  unite(item1, item2, col = "items", sep = " <--> ") %>%
  transmute(observed_rank = items,
            distance_rank = dense_rank(distance)) %>%
  arrange(distance_rank) %>%
  # And now we'll line this up with the MDS results
  left_join(
    tidy_nonmetric_mds_distances %>%
      unite(item1, item2, col = "items", sep = " <--> ") %>%
      transmute(mds_rank = items,
                distance_rank = dense_rank(distance)) %>%
      arrange(distance_rank),
    # This is the line that lines them up (`by = `)
    by = "distance_rank"
  ) %>%
  # And finally we'll check which are the same
  mutate(match = observed_rank == mds_rank) %>%
  count(match)
```

It certainly doesn't seem like we have!  Yikes!  I think a higher-dimensional solution is certainly required to adequately capture the configuration of these products.

## Wrap up

To be fair, saying "Yikes!" is probably a little overblown.  If we examined the tables above I used to compare the observed and estimated ranks in more detail, we'd see that the variation is quite small, for example, for the non-metric data:

```{r echo=FALSE}
tidy_descriptive_distances %>%
  unite(item1, item2, col = "items", sep = " <--> ") %>%
  transmute(observed_rank = items,
            distance_rank = dense_rank(distance)) %>%
  arrange(distance_rank) %>%
  # And now we'll line this up with the MDS results
  left_join(
    tidy_nonmetric_mds_distances %>%
      unite(item1, item2, col = "items", sep = " <--> ") %>%
      transmute(mds_rank = items,
                distance_rank = dense_rank(distance)) %>%
      arrange(distance_rank),
    # This is the line that lines them up (`by = `)
    by = "distance_rank"
  ) %>%
  # And finally we'll check which are the same
  mutate(match = observed_rank == mds_rank)
```

As we can see, while indeed there are rank reversals, they are relatively minor: it isn't like samples that are close in the actual distance matrix are ending up being very far in the non-metric MDS 2-dimensional solution.

## Packages used in this chapter

```{r}
sessionInfo()
```