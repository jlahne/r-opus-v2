@article{abdiAnalyzing2007,
  title = {Analyzing Assessors and Products in Sorting Tasks: {{DISTATIS}}, Theory and Applications},
  shorttitle = {Analyzing Assessors and Products in Sorting Tasks},
  author = {Abdi, H. and Valentin, D. and Chollet, S. and Chrea, C.},
  year = {2007},
  month = jun,
  journal = {Food Quality and Preference},
  volume = {18},
  number = {4},
  pages = {627--640},
  issn = {09503293},
  doi = {10.1016/j.foodqual.2006.09.003},
  urldate = {2018-08-22},
  abstract = {In this paper we present a new method called DISTATIS that can be applied to the analysis of sorting data. DISTATIS is a generalization of classical multidimensional scaling which allows one to analyze 3-ways distance tables. When used for analyzing sorting tasks, DISTATIS takes into account individual sorting data. Specifically, when DISTATIS is used to analyze the results of an experiment in which several assessors sort a set of products, we obtain two types of maps: One for the assessors and one for the products. In these maps, the proximity between two points reflects their similarity, and therefore these maps can be read using the same rules as standard metric multidimensional scaling methods or principal component analysis. Technically, DISTATIS starts by transforming the individual sorting data into cross-product matrices as in classical MDS and evaluating the similarity between these matrices (using Escoufier's RV coefficient). Then it computes a compromise matrix which is the best aggregate (in the least square sense, as STATIS does) of the individual cross-product matrices and analyzes it with PCA. The individual matrices are then projected onto the compromise space. In this paper, we present a short tutorial, and we illustrate how to use DISTATIS with a sorting task in which ten assessors evaluated eight beers. We also provide some insights into how DISTATIS evaluates the similarity between assessors.},
  langid = {english},
  keywords = {3-Way analysis,distatis,Multidimensional scaling,Rand coefficient,rv-coefficient,Sorting task,statis},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi et al_2007_Analyzing assessors and products in sorting tasks.pdf}
}

@incollection{abdiCorrespondence,
  title = {Correspondence Analysis},
  booktitle = {Encyclopedia of {{Social Networks}} and {{Mining}}},
  author = {Abdi, H and B{\'e}ra, M},
  year = {2015},
  editor = {Alhajj, R. and Rokne, J.},
  pages = {275--284},
  publisher = {{Springer Verlag}},
  address = {{New York}},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi_BÃ©ra, M_Correspondence analysis.pdf}
}

@article{abdiMultiple2013,
  title = {Multiple Factor Analysis: Principal Component Analysis for Multitable and Multiblock Data Sets: {{Multiple}} Factor Analysis},
  shorttitle = {Multiple Factor Analysis},
  author = {Abdi, Herv{\'e} and Williams, Lynne J. and Valentin, Domininique},
  year = {2013},
  month = mar,
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  volume = {5},
  number = {2},
  pages = {149--179},
  issn = {19395108},
  doi = {10.1002/wics.1246},
  urldate = {2018-08-22},
  langid = {english},
  keywords = {barycentric discriminant analysis (BADA),consensus PCA,generalized Procrustes analysis (GPA),generalized singular value decomposition,INDSCAL,multiblock barycentric discriminant analysis (MUDICA),multiblock correspondence analysis,multiblock PCA,multiple factor analysis (MFA),multiple factor analysis barycentric discriminant analysis (MUFABADA),multiple factorial analysis,multitable PCA,principal component analysis,STATIS},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi et al_2013_Multiple factor analysis.pdf}
}

@incollection{abdiPartial2013,
  title = {Partial {{Least Squares Methods}}: {{Partial Least Squares Correlation}} and {{Partial Least Square Regression}}},
  shorttitle = {Partial {{Least Squares Methods}}},
  booktitle = {Computational {{Toxicology}}},
  author = {Abdi, Herv{\'e} and Williams, Lynne J.},
  editor = {Reisfeld, Brad and Mayeno, Arthur N.},
  year = {2013},
  volume = {930},
  pages = {549--579},
  publisher = {{Humana Press}},
  address = {{Totowa, NJ}},
  doi = {10.1007/978-1-62703-059-5_23},
  urldate = {2018-08-22},
  abstract = {Partial least square (PLS) methods (also sometimes called projection to latent structures) relate the information present in two data tables that collect measurements on the same set of observations. PLS methods proceed by deriving latent variables which are (optimal) linear combinations of the variables of a data table. When the goal is to find the shared information between two tables, the approach is equivalent to a correlation problem and the technique is then called partial least square correlation (PLSC) (also sometimes called PLS-SVD). In this case there are two sets of latent variables (one set per table), and these latent variables are required to have maximal covariance. When the goal is to predict one data table the other one, the technique is then called partial least square regression. In this case there is one set of latent variables (derived from the predictor table) and these latent variables are required to give the best possible prediction. In this paper we present and illustrate PLSC and PLSR and show how these descriptive multivariate analysis techniques can be extended to deal with inferential questions by using cross-validation techniques such as the bootstrap and permutation tests.},
  isbn = {978-1-62703-058-8 978-1-62703-059-5},
  langid = {english},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi_Williams_2013_Partial Least Squares Methods.pdf}
}

@article{abdiPrincipal2010,
  title = {Principal {{Component Analysis}}},
  author = {Abdi, Herve and Williams, Lynne J},
  year = {2010},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  volume = {2},
  pages = {433--459},
  abstract = {Principal component analysis (pca) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the pca model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. Pca can be generalized as correspondence analysis (ca) in order to handle qualitative variables and as multiple factor analysis (mfa) in order to handle heterogenous sets of variables. Mathematically, pca depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (svd) of rectangular matrices.},
  langid = {english},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi_Williams_Principal Component Analysis.pdf}
}

@article{abdiSTATIS2012,
  title = {{{STATIS}} and {{DISTATIS}}: Optimum Multitable Principal Component Analysis and Three Way Metric Multidimensional Scaling: {{STATIS}} and {{DISTATIS}}},
  shorttitle = {{{STATIS}} and {{DISTATIS}}},
  author = {Abdi, H. and Williams, L.J. and Valentin, D. and {Bennani-Dosse}, M.},
  year = {2012},
  month = mar,
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  volume = {4},
  number = {2},
  pages = {124--167},
  issn = {19395108},
  doi = {10.1002/wics.198},
  urldate = {2018-08-22},
  langid = {english},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Abdi et al_2012_STATIS and DISTATIS.pdf}
}

@article{brockhoffTaking2015,
  title = {Taking Individual Scaling Differences into Account by Analyzing Profile Data with the {{Mixed Assessor Model}}},
  author = {Brockhoff, Per Bruun and Schlich, Pascal and Skovgaard, Ib},
  year = {2015},
  month = jan,
  journal = {Food Quality and Preference},
  volume = {39},
  pages = {156--166},
  issn = {0950-3293},
  doi = {10.1016/j.foodqual.2014.07.005},
  abstract = {Scale range differences between individual assessors will often constitute a non-trivial part of the assessor-by-product interaction in sensory profile data (Brockhoff, 2003, 1998; Brockhoff and Skovgaard, 1994). We suggest a new mixed model ANOVA analysis approach, the Mixed Assessor Model (MAM) that properly takes this into account by a simple inclusion of the product averages as a covariate in the modeling and allowing the covariate regression coefficients to depend on the assessor. This gives a more powerful analysis by removing the scaling difference from the error term and proper confidence limits are deduced that include scaling difference in the error term to the proper extent. A meta study of 8619 sensory attributes from 369 sensory profile data sets from SensoBase (www.sensobase.fr) is conducted. In 45.3\% of all attributes scaling heterogeneity is present (P-value {$<$}0.05). For the 33.9\% of the attributes having a product difference P-value in an intermediate range by the traditional approach, the new approach resulted in a clearly more significant result for 42.3\% of these cases. Overall, the new approach claimed significant product difference (P-value {$<$}0.05) for 66.1\% of the attributes compared to the 60.3\% of traditional approach. Still, the new, and non-symmetrical, confidence limits are more often wider than narrower compared to the classical ones: in 72.6\% of all cases.},
  keywords = {Analysis of variance,Assessor differences,Disagreement,Mixed model,Scaling differences,Sensory profile data},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Brockhoff et al_2015_Taking individual scaling differences into account by analyzing profile data.pdf}
}

@incollection{courcouxFree2023,
  title = {Free Sorting as a Sensory Profiling Technique for Product Development},
  booktitle = {Rapid {{Sensory Profiling Techniques}}},
  author = {Courcoux, P. and Faye, P. and Qannari, E. M.},
  editor = {Delarue, J. and Lawlor, J. Benjamin},
  year = {2023},
  edition = {2nd},
  publisher = {{Woodhead}}
}

@article{dettmarPrincipal2020,
  title = {Beyond Principal Component Analysis ({{PCA}}) of Product Means: {{Toward}} a Psychometric View on Sensory Profiling Data},
  author = {Dettmar, Burkhard and Peltier, Caroline and Schlich, Pascal},
  year = {2020},
  month = apr,
  journal = {Journal of Sensory Studies},
  volume = {35},
  number = {2},
  pages = {e12555},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0887-8250},
  doi = {10.1111/joss.12555},
  urldate = {2022-11-08},
  abstract = {Abstract Principal component analysis (PCA) has its origin in psychology, where it was developed as a psychometric tool to measure latent variables of human cognition, personality, or behavior. This psychometric approach is also suitable to measure human perception based on sensory profiling data. To do so, we apply the PCA to a matrix that maintains the individual panelist's judgments, the matrix structure is in line with the ?Tucker-1 common loadings model.? Our approach (?Tucker-1 PCA?) differs from the routine method of analyzing sensory profiling data, where PCA is applied to the matrix of mean scores of the product-by-attribute table (?Means-PCA?). This article discusses the specific properties of the Tucker-1 PCA and compares it to the Means-PCA via a meta-analysis on 422 datasets from Sensobase, a collection of sensory profiling studies. Tucker-1 PCA provides advantages over Means-PCA in terms of dimensionality, interpretability, and replicability of the factor structures. Practical Applications Tucker-1 PCA is an easily applicable variant of PCA for sensory profiling data. Like Means-PCA, it can be used to create product maps. It provides, however, more stable and easier interpretable axes. As a psychometric tool, Tucker-1 PCA provides a measurement of products on underlying sensory dimensions.},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Dettmar et al_2020_Beyond principal component analysis (PCA) of product means.pdf}
}

@article{gowerGeneralized1975,
  title = {Generalized Procrustes Analysis},
  author = {Gower, John C.},
  year = {1975},
  journal = {Psychometrika},
  volume = {40},
  pages = {33--51},
  publisher = {{Springer}},
  isbn = {0033-3123},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Gower_1975_Generalized procrustes analysis.pdf}
}

@book{greenacre2017correspondence,
  title={Correspondence analysis in practice},
  author={Greenacre, Michael},
  year={2017},
  publisher={CRC press}
}


@book{heymannSensory2017,
  title = {Sensory and {{Instrumental Evaluation}} of {{Alcoholic Beverages}}},
  shorttitle = {Sensory and {{Instrumental Evaluation}} of {{Alcoholic Beverages}}},
  author = {Heymann, H. and Ebeler, Susan E.},
  year = {2017},
  publisher = {{Elsevier}},
  address = {{London}},
  keywords = {\#nosource}
}

@article{josseMeasuring2016,
  title = {Measuring Multivariate Association and Beyond},
  author = {Josse, Julie and Holmes, Susan},
  year = {2016},
  journal = {Statistics Surveys},
  volume = {10},
  number = {0},
  pages = {132--167},
  issn = {1935-7516},
  doi = {10.1214/16-SS116},
  urldate = {2020-05-06},
  abstract = {Simple correlation coefficients between two variables have been generalized to measure association between two matrices in many ways. Coefficients such as the RV coefficient, the distance covariance (dCov) coefficient and kernel based coefficients are being used by different research communities. Scientists use these coefficients to test whether two random vectors are linked. Once it has been ascertained that there is such association through testing, then a next step, often ignored, is to explore and uncover the association's underlying patterns.},
  langid = {english},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Josse_Holmes_2016_Measuring multivariate association and beyond.pdf}
}

@article{kruschkeDoing2014,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John},
  year = {2014},
  publisher = {{Academic Press}},
  isbn = {0124059163}
}

@article{peltierCanonical2015,
  title = {Canonical {{Variate Analysis}} of {{Sensory Profiling Data}}},
  shorttitle = {Canonical {{Variate Analysis}} of {{Sensory Profiling Data}}},
  author = {Peltier, C. and Visalli, M. and Schlich, P.},
  year = {2015},
  journal = {Journal of Sensory Studies},
  volume = {30},
  number = {2015},
  pages = {316--328},
  keywords = {\#nosource},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Peltier et al_2015_Canonical Variate Analysis of Sensory Profiling Data2.pdf}
}

@article{qannariPerformance1998,
  title = {Performance Indices and Isotropic Scaling Factors in Sensory Profiling},
  author = {Qannari, El Mostafa and MacFie, Halliday J.H and Courcoux, Philippe},
  year = {1998},
  month = oct,
  journal = {Food Quality and Preference},
  volume = {10},
  number = {1},
  pages = {17--21},
  issn = {0950-3293},
  doi = {10.1016/S0950-3293(98)00033-0},
  abstract = {A new procedure for the determination of the isotropic scaling factors in Generalised Procrustes Analysis is discussed. A noteworthy feature of this procedure is that each isotropic scaling factor is shown to be the product of a standardisation scalar which adjusts for the differences in range of scoring among assessors, and a performance index. An overall performance index for the whole panel is also discussed. The performance indices can be useful in improving the performance of the panel by pointing out whether further training is required for the whole panel or for some specific assessors. Once the isotropic scaling factors are determined, it is possible to derive a group average configuration using one of several algorithms proposed in the statistical literature which aim at matching a set of configurations by means of rotations. A data set is analysed and a simulation study is undertaken in order to demonstrate the method, and the outcomes are compared to those obtained by means of Gower's algorithm for Generalised Procrustes Analysis.},
  keywords = {generalised procrustes analysis,isotropic scaling factor,performance indices,Sensory analysis}
}

@book{rencherMethods2002,
  title = {Methods of Multivariate Analysis},
  author = {Rencher, Alvin C.},
  year = {2002},
  series = {Wiley Series in Probability and Mathematical Statistics},
  edition = {2nd ed},
  publisher = {{J. Wiley}},
  address = {{New York}},
  isbn = {978-0-471-41889-4},
  langid = {english},
  lccn = {QA278 .R45 2002},
  keywords = {Multivariate analysis},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Rencher_2002_Methods of multivariate analysis.pdf}
}

@article{tomicComparison2015,
  title = {A Comparison of Generalised Procrustes Analysis and Multiple Factor Analysis for Projective Mapping Data},
  author = {Tomic, O. and Berget, I. and N{\ae}s, T.},
  year = {2015},
  month = jul,
  journal = {Food Quality and Preference},
  volume = {43},
  pages = {34--46},
  issn = {0950-3293},
  doi = {10.1016/j.foodqual.2015.02.004},
  abstract = {Generalised procrustes analysis and multiple factor analysis are multivariate statistical methods that belong to the family of multiblock methods. Both methods are often used for analysis of data from projective mapping (a.k.a. Napping). In this study, generalised procrustes analysis and multiple factor analysis are compared for a number of simulated and real data sets. The type of data used in this study were (I) random data from Monte Carlo simulations; (II) constructed data that were manipulated according to some specific criteria; (III) real data from nine Napping experiments. Focus will be on similarities of the consensus solutions. In addition we considered interpretation of the RV coefficient and individual differences between assessors.},
  keywords = {Consumer test,Generalised procrustes analysis,GPA,MFA,Multiblock method,Multiple factor analysis,Napping,Projective mapping,RV coefficient},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Tomic et al_2015_A comparison of generalised procrustes analysis and multiple factor analysis.pdf}
}

@article{yenketCOMPARISON2011,
  title = {A {{COMPARISON OF SEVEN PREFERENCE MAPPING TECHNIQUES USING FOUR SOFTWARE PROGRAMS}}: {{COMPARISON OF MAPPING TECHNIQUES}}},
  shorttitle = {A {{COMPARISON OF SEVEN PREFERENCE MAPPING TECHNIQUES USING FOUR SOFTWARE PROGRAMS}}},
  author = {Yenket, Renoo and Chambers IV, Edgar and Adhikari, Koushik},
  year = {2011},
  month = apr,
  journal = {Journal of Sensory Studies},
  volume = {26},
  number = {2},
  pages = {135--150},
  issn = {08878250},
  doi = {10.1111/j.1745-459X.2011.00330.x},
  urldate = {2019-09-19},
  abstract = {Various methods are used to create a preference map based on different theories to model and analyze relationships between product descriptors and consumer preferences. Several programs offer solutions to understand influences and relationships between a descriptive sensory profile and consumer liking, but researchers need to know the (dis)advantages and (dis)similarities of these programs. This study compares the advantages and disadvantages of four statistical software programs and seven multivariate techniques for three empirical studies: milk, paint and fragrance. Internal and external preference mapping are included in this study. No multivariate method consistently generated a high percentage of consumers who mapped closest to their most-liked products. Also, neither the variance nor the complete solution was explained among descriptors and consumers. Of particular interest is that the high percent variance explained in descriptors and/or consumers did not guarantee a preference mean vector that was close to the most-liked product. For uncomplicated data, researchers can use any method/program to create a preference map when consumer data are highly homogenous in product liking patterns. XLSTAT PLS2 (Addinsoft, New York, NY) and Unscrambler PLS2 (passified; CAMO Software Inc., Woodbridge, NJ) are recommended for less homogenous consumer data. For complex heterogeneous data, multidimensional preference analysis is recommended for understanding consumer preference.},
  langid = {english},
  file = {/Users/jake/Library/CloudStorage/Dropbox/Work/Zotero PDF Files/Yenket et al_2011_A COMPARISON OF SEVEN PREFERENCE MAPPING TECHNIQUES USING FOUR SOFTWARE PROGRAMS.pdf}
}

@book{kurzDoingBayesianDataAnalysis2023,
  title = {Doing {{Bayesian}} data analysis in brms and the tidyverse},
  author = {Kurz, A. Solomon},
  year = {2023},
  month = {1},
  edition = {Version 1.1.0},
  url = {https://bookdown.org/content/3686/}
}